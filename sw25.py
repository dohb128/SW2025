# -*- coding: utf-8 -*-
"""SW25.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bGHj9cGky2o_dd1aE8OnZAZMkCnafqFq
"""

!apt-get update -qq
!apt-get install fonts-nanum -qq

import matplotlib.font_manager as fm
import matplotlib.pyplot as plt

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rc('font', family='NanumGothic')
import matplotlib as mpl
import os

# 2. matplotlib ìºì‹œ ê°•ì œ ì‚­ì œ (ì¤‘ìš”)
import shutil
matplotlib_cache_dir = mpl.get_cachedir()
if os.path.exists(matplotlib_cache_dir):
    shutil.rmtree(matplotlib_cache_dir)

# ì„¤ì¹˜ëœ ë‚˜ëˆ”ê³ ë”• ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
fontprop = fm.FontProperties(fname=font_path)

# ì „ì—­ ì„¤ì •
font_name = fontprop.get_name()  # í°íŠ¸ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
mpl.rcParams['font.family'] = font_name  # NanumGothicìœ¼ë¡œ í™•ì‹¤í•˜ê²Œ ì„¤ì •
plt.rcParams['axes.unicode_minus'] = False

# í™•ì¸
print("ì„¤ì •ëœ í°íŠ¸ ì´ë¦„:", font_name)

plt.plot([1, 2, 3], [1, 4, 9])
plt.title("í…ŒìŠ¤íŠ¸ - í•œê¸€ ì˜ ë‚˜ì˜¤ë‚˜ìš”?", fontproperties=fontprop)
plt.show()

# ì‹œìŠ¤í…œ ëª…ë ¹ì–´ë¡œ ì••ì¶• í•´ì œ (í•œê¸€ ê¹¨ì§ ë°©ì§€)
!apt-get install -y unzip
!unzip -O cp949 '/content/drive/MyDrive/ìë£Œ.zip' -d '/content/dataset'

# ğŸš€ Transfer Learning + Custom ê°•í™” ëª¨ë¸

# ê¸°ë³¸ import
import os
import numpy as np
import random
import json
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import img_to_array
from tqdm import tqdm

import warnings
warnings.filterwarnings('ignore')

# TensorFlow import
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

# ğŸ“‚ íŒŒì¼ ê²½ë¡œ ì„¤ì •
base_path = '/content/dataset'

class_dirs = {
    'ê²°ë§‰ì—¼_ë¬´': os.path.join(base_path, 'ê²°ë§‰ì—¼', 'ë¬´'),
    'ê²°ë§‰ì—¼_ìœ ': os.path.join(base_path, 'ê²°ë§‰ì—¼', 'ìœ '),
    'ë°±ë‚´ì¥_ë¬´': os.path.join(base_path, 'ë°±ë‚´ì¥', 'ë¬´'),
    'ë°±ë‚´ì¥_ë¹„ì„±ìˆ™': os.path.join(base_path, 'ë°±ë‚´ì¥', 'ë¹„ì„±ìˆ™'),
    'ë°±ë‚´ì¥_ì„±ìˆ™': os.path.join(base_path, 'ë°±ë‚´ì¥', 'ì„±ìˆ™'),
    'ë°±ë‚´ì¥_ì´ˆê¸°': os.path.join(base_path, 'ë°±ë‚´ì¥', 'ì´ˆê¸°')
}

label_to_idx = {label: idx for idx, label in enumerate(class_dirs)}
idx_to_label = {v: k for k, v in label_to_idx.items()}

# ğŸ¯ ì´ë¯¸ì§€ ë¡œë“œ
images = []
labels = []
bbox_error_count = 0

random.seed(42)

for label_name, dir_path in class_dirs.items():
    json_files = [f for f in os.listdir(dir_path) if f.endswith('.json')]
    selected_json_files = random.sample(json_files, min(len(json_files), 500))

    for filename in tqdm(selected_json_files, desc=f"Loading {label_name}"):
        json_path = os.path.join(dir_path, filename)
        try:
            with open(json_path, 'r') as f:
                data = json.load(f)

            image_filename = 'crop_' + data['images']['meta']['file_name']
            image_path = os.path.join(dir_path, image_filename)
            if not os.path.exists(image_path):
                continue

            img = Image.open(image_path).convert('RGB')

            try:
                bbox = data['label']['label_bbox']
                x_min, y_min, x_max, y_max = map(int, bbox)
                cropped = img.crop((x_min, y_min, x_max, y_max)).resize((224, 224))
            except Exception:
                bbox_error_count += 1
                cropped = img.resize((224, 224))

            images.append(img_to_array(cropped))
            labels.append(label_to_idx[label_name])

        except Exception as e:
            print(f"âš ï¸ ì˜¤ë¥˜ - {filename}: {e}")

print(f"\nâš¡ bbox ì—ëŸ¬ë¡œ ì „ì²´ ì´ë¯¸ì§€ ì‚¬ìš©ëœ íŒŒì¼ ìˆ˜: {bbox_error_count}ê°œ")
print(f"âœ… ìµœì¢… ë¡œë”©ëœ ì´ë¯¸ì§€ ìˆ˜: {len(images)}ê°œ")
print("\nğŸš€ ë°ì´í„° ë¡œë“œ ì™„ë£Œ. ì´ì œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...\n")

# ë°ì´í„° ì „ì²˜ë¦¬
X = np.array(images, dtype='float32')
X = preprocess_input(X)  # MobileNetV2 ì „ì²˜ë¦¬

y = to_categorical(labels, num_classes=len(label_to_idx))

# ë°ì´í„° ë¶„í• 
X_temp, X_train, y_temp, y_train = train_test_split(X, y, test_size=0.7, random_state=42, stratify=y)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=3/7, random_state=42, stratify=y_temp)

# ğŸ“š MobileNetV2 ê¸°ë°˜ ëª¨ë¸ ë§Œë“¤ê¸°
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False  # Feature extractorë¡œë§Œ ì‚¬ìš©

x = base_model.output
x = Conv2D(64, (3,3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)
x = MaxPooling2D(pool_size=(2,2))(x)

x = Conv2D(128, (3,3), activation='relu', padding='same')(x)
x = BatchNormalization()(x)
x = MaxPooling2D(pool_size=(2,2))(x)

x = GlobalAveragePooling2D()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
output = Dense(len(label_to_idx), activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output)

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# ğŸ‹ï¸ í•™ìŠµ ì‹œì‘
model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=8,
    batch_size=16
)

# ğŸ“ˆ í…ŒìŠ¤íŠ¸ì…‹ í‰ê°€
predictions = model.predict(X_test)
y_pred = np.argmax(predictions, axis=1)
y_true = np.argmax(y_test, axis=1)

# Confusion Matrix ì¶œë ¥
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=[idx_to_label[i] for i in range(len(label_to_idx))],
            yticklabels=[idx_to_label[i] for i in range(len(label_to_idx))])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Classification Report ì¶œë ¥
print("\n[Classification Report]")
print(classification_report(y_true, y_pred, target_names=[idx_to_label[i] for i in range(len(label_to_idx))]))

import os
import numpy as np
from PIL import Image
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

# --- í…ŒìŠ¤íŠ¸ í´ë” ê²½ë¡œ ---
test_folder = '/content/dataset/í…ŒìŠ¤íŠ¸'

# --- íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ---
test_images = [f for f in os.listdir(test_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]

# --- íŒŒì¼ëª… íŒ¨í„´ì„ ì‹¤ì œ ë¼ë²¨ë¡œ ë§¤í•‘í•˜ëŠ” í•¨ìˆ˜ ---
def get_true_label_from_filename(filename):
    if filename.startswith('ê²°ìœ '):
        return 'ê²°ë§‰ì—¼_ìœ '
    elif filename.startswith('ê²°ë¬´'):
        return 'ê²°ë§‰ì—¼_ë¬´'
    elif filename.startswith('ë°±ë¬´'):
        return 'ë°±ë‚´ì¥_ë¬´'
    elif filename.startswith('ë°±ì´ˆ'):
        return 'ë°±ë‚´ì¥_ì´ˆê¸°'
    elif filename.startswith('ë°±ë¹„ì„±'):
        return 'ë°±ë‚´ì¥_ë¹„ì„±ìˆ™'
    elif filename.startswith('ë°±ì„±'):
        return 'ë°±ë‚´ì¥_ì„±ìˆ™'
    else:
        return None  # ì˜ˆì™¸ì²˜ë¦¬ìš©

# --- í…ŒìŠ¤íŠ¸ ìˆ˜í–‰ ---
correct = 0
total = 0

for img_name in test_images:
    img_path = os.path.join(test_folder, img_name)

    # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
    img = Image.open(img_path).convert('RGB')
    img = img.resize((224, 224))
    img_array = np.array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)

    # ëª¨ë¸ ì˜ˆì¸¡
    pred = model.predict(img_array)
    pred_class = np.argmax(pred, axis=1)[0]
    pred_label = idx_to_label[pred_class]

    # ì‹¤ì œ ì •ë‹µ ì¶”ë¡ 
    true_label = get_true_label_from_filename(img_name)

    # ë¹„êµ
    is_correct = (pred_label == true_label)
    if is_correct:
        correct += 1
    total += 1

    # ê²°ê³¼ ì¶œë ¥
    result_text = "â­• ì •ë‹µ" if is_correct else "âŒ ì˜¤ë‹µ"
    print(f"ğŸ–¼ï¸ íŒŒì¼ëª…: {img_name} â†’ ì˜ˆì¸¡: {pred_label} / ì •ë‹µ: {true_label} â†’ {result_text}")

# --- ìµœì¢… ì •í™•ë„ ì¶œë ¥ ---
accuracy = correct / total * 100
print(f"\nğŸ¯ ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.2f}% ({correct}/{total}ê°œ ë§ì¶¤)")